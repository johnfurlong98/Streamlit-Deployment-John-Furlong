{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/conor/Desktop/Deploy/dashboard/notebook/dashboard/notebook/raw_data/house_prices_records.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m inherited_houses_file \u001b[38;5;241m=\u001b[39m BASE_DIR \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdashboard\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnotebook\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw_data\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minherited_houses.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Import datasets\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m house_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhouse_data_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m inherited_houses \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(inherited_houses_file)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHouse Data Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhouse_data\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Deploy/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Deploy/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Desktop/Deploy/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Deploy/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Desktop/Deploy/.venv/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/conor/Desktop/Deploy/dashboard/notebook/dashboard/notebook/raw_data/house_prices_records.csv'"
     ]
    }
   ],
   "source": [
    "# house_price_prediction.ipynb\n",
    "\n",
    "# Import essential libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pickle\n",
    "import warnings\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, ElasticNetCV, LassoCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from pathlib import Path\n",
    "\n",
    "# Ignore warnings for clean output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set BASE_DIR to the current working directory for Jupyter Notebooks\n",
    "BASE_DIR = Path(os.getcwd())\n",
    "\n",
    "# Define directories\n",
    "data_dir = BASE_DIR / 'data'\n",
    "models_dir = BASE_DIR / 'data' / 'models'  # Subdirectory for models\n",
    "os.makedirs(models_dir, exist_ok=True)  # Ensure models directory exists\n",
    "\n",
    "# Set file paths\n",
    "house_data_file = BASE_DIR /'raw_data' / 'house_prices_records.csv'\n",
    "inherited_houses_file = BASE_DIR / 'raw_data' / 'inherited_houses.csv'\n",
    "\n",
    "# Import datasets\n",
    "house_data = pd.read_csv(house_data_file)\n",
    "inherited_houses = pd.read_csv(inherited_houses_file)\n",
    "\n",
    "print(f\"House Data Shape: {house_data.shape}\")\n",
    "print(f\"Inherited Houses Shape: {inherited_houses.shape}\")\n",
    "\n",
    "# Display first few rows of the datasets\n",
    "print(\"First few rows of house_data:\")\n",
    "print(house_data.head())\n",
    "print(\"First few rows of inherited_houses:\")\n",
    "print(inherited_houses.head())\n",
    "\n",
    "# Apply log transformation to SalePrice\n",
    "# The sale prices are right-skewed; applying log transformation to normalize the distribution\n",
    "house_data['SalePrice_Log'] = np.log1p(house_data['SalePrice'])\n",
    "\n",
    "# Handle missing values in house_data\n",
    "print(\"\\nHandling missing values in house_data...\")\n",
    "\n",
    "# List of features where missing values likely indicate absence of the feature\n",
    "zero_fill_features = ['2ndFlrSF', 'EnclosedPorch', 'MasVnrArea', 'WoodDeckSF',\n",
    "                      'BsmtFinSF1', 'TotalBsmtSF', '1stFlrSF', 'BsmtUnfSF']\n",
    "\n",
    "for feature in zero_fill_features:\n",
    "    house_data[feature].fillna(0, inplace=True)\n",
    "    print(f\"Filled missing values in {feature} with 0.\")\n",
    "\n",
    "# Fill missing categorical features with mode or default value\n",
    "categorical_mode_fill = {\n",
    "    'BedroomAbvGr': house_data['BedroomAbvGr'].mode()[0],\n",
    "    'BsmtFinType1': 'None',\n",
    "    'GarageFinish': 'Unf',\n",
    "    'BsmtExposure': 'No',\n",
    "    'KitchenQual': 'TA'\n",
    "}\n",
    "\n",
    "for feature, value in categorical_mode_fill.items():\n",
    "    house_data[feature].fillna(value, inplace=True)\n",
    "    print(f\"Filled missing values in {feature} with '{value}'.\")\n",
    "\n",
    "# Fill missing numerical features with median\n",
    "numerical_median_fill = ['GarageYrBlt', 'LotFrontage', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd']\n",
    "\n",
    "for feature in numerical_median_fill:\n",
    "    median_value = house_data[feature].median()\n",
    "    house_data[feature].fillna(median_value, inplace=True)\n",
    "    print(f\"Filled missing values in {feature} with median value {median_value}.\")\n",
    "\n",
    "# Verify that there are no missing values left\n",
    "print(\"\\nChecking for remaining missing values:\")\n",
    "print(house_data.isnull().sum()[house_data.isnull().sum() > 0])\n",
    "\n",
    "# Encode categorical features\n",
    "print(\"\\nEncoding categorical features in house_data...\")\n",
    "\n",
    "# Define mappings for ordinal categorical features based on their definitions\n",
    "ordinal_mappings = {\n",
    "    'BsmtFinType1': {'None': 0, 'Unf': 1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6},\n",
    "    'KitchenQual': {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n",
    "    'BsmtExposure': {'None': 0, 'No': 1, 'Mn': 2, 'Av': 3, 'Gd': 4},\n",
    "    'GarageFinish': {'None': 0, 'Unf': 1, 'RFn': 2, 'Fin': 3}\n",
    "}\n",
    "\n",
    "for col, mapping in ordinal_mappings.items():\n",
    "    if col in house_data.columns:\n",
    "        house_data[col] = house_data[col].map(mapping)\n",
    "        print(f\"Encoded {col} using ordinal mapping.\")\n",
    "\n",
    "# Identify numeric features\n",
    "numeric_feats = house_data.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Check skewness of numeric features\n",
    "skewness = house_data[numeric_feats].apply(lambda x: x.skew()).sort_values(ascending=False)\n",
    "print(\"\\nSkewness of numeric features:\")\n",
    "print(skewness)\n",
    "\n",
    "# Features with high skewness (threshold can be adjusted)\n",
    "skewed_features = skewness[abs(skewness) > 0.75].index.tolist()\n",
    "print(\"\\nFeatures with high skewness (|skewness| > 0.75):\")\n",
    "print(skewed_features)\n",
    "\n",
    "# Apply log or box-cox transformation to skewed features\n",
    "print(\"\\nTransforming skewed features in house_data...\")\n",
    "\n",
    "# Dictionary to store lambda values for box-cox transformation\n",
    "lam_dict = {}\n",
    "\n",
    "for feat in skewed_features:\n",
    "    if (house_data[feat] <= 0).any():\n",
    "        # If the feature has zero or negative values, use log1p transformation\n",
    "        house_data[feat] = np.log1p(house_data[feat])\n",
    "        print(f\"Applied log1p transformation to {feat}.\")\n",
    "    else:\n",
    "        # Apply box-cox transformation\n",
    "        try:\n",
    "            transformed_data, lam = boxcox(house_data[feat])\n",
    "            house_data[feat] = transformed_data\n",
    "            lam_dict[feat] = lam\n",
    "            print(f\"Applied box-cox transformation to {feat} with lambda {lam:.4f}.\")\n",
    "        except ValueError:\n",
    "            # If box-cox fails, use log1p\n",
    "            house_data[feat] = np.log1p(house_data[feat])\n",
    "            print(f\"Applied log1p transformation to {feat} (box-cox failed).\")\n",
    "\n",
    "# Save skewed features and lambda values for future use\n",
    "with open(models_dir / 'skewed_features.pkl', 'wb') as f:\n",
    "    pickle.dump(skewed_features, f)\n",
    "with open(models_dir / 'lam_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(lam_dict, f)\n",
    "\n",
    "# Feature engineering\n",
    "print(\"\\nPerforming feature engineering in house_data...\")\n",
    "\n",
    "# Create new features based on domain knowledge\n",
    "house_data['TotalSF'] = house_data['TotalBsmtSF'] + house_data['1stFlrSF'] + house_data['2ndFlrSF']\n",
    "print(\"Created TotalSF feature as sum of TotalBsmtSF, 1stFlrSF, and 2ndFlrSF.\")\n",
    "\n",
    "house_data['Qual_TotalSF'] = house_data['OverallQual'] * house_data['TotalSF']\n",
    "print(\"Created Qual_TotalSF feature as product of OverallQual and TotalSF.\")\n",
    "\n",
    "# Prepare data for modeling\n",
    "print(\"\\nPreparing data for modeling...\")\n",
    "\n",
    "# Drop unnecessary columns\n",
    "X = house_data.drop(['SalePrice', 'SalePrice_Log'], axis=1, errors='ignore')\n",
    "y = house_data['SalePrice_Log']\n",
    "\n",
    "# Define the features based on the provided metadata\n",
    "feature_list = [\n",
    "    '1stFlrSF', '2ndFlrSF', 'BedroomAbvGr', 'BsmtExposure', 'BsmtFinType1',\n",
    "    'BsmtFinSF1', 'BsmtUnfSF', 'TotalBsmtSF', 'GarageArea', 'GarageFinish',\n",
    "    'GarageYrBlt', 'GrLivArea', 'KitchenQual', 'LotArea', 'LotFrontage',\n",
    "    'MasVnrArea', 'EnclosedPorch', 'OpenPorchSF', 'OverallCond', 'OverallQual',\n",
    "    'WoodDeckSF', 'YearBuilt', 'YearRemodAdd', 'TotalSF', 'Qual_TotalSF'  # Include engineered features\n",
    "]\n",
    "\n",
    "# Ensure the features are in X\n",
    "X = X[feature_list]\n",
    "\n",
    "# Feature selection using Random Forest\n",
    "print(\"\\nPerforming feature selection using Random Forest...\")\n",
    "\n",
    "# Use Random Forest to estimate feature importances\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X, y)\n",
    "\n",
    "# Get feature importances\n",
    "importances = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "print(\"Feature importances from Random Forest:\")\n",
    "print(importances)\n",
    "\n",
    "# Select top features (e.g., top 20)\n",
    "selected_features = importances[:20].index.tolist()\n",
    "print(\"\\nSelected top features for modeling:\")\n",
    "print(selected_features)\n",
    "\n",
    "# Save selected features for future use\n",
    "with open(models_dir / 'selected_features.pkl', 'wb') as f:\n",
    "    pickle.dump(selected_features, f)\n",
    "\n",
    "# Keep only selected features\n",
    "X = X[selected_features]\n",
    "\n",
    "# Split data into training and test sets\n",
    "print(\"\\nSplitting data into training and test sets...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save train and test data for the dashboard\n",
    "joblib.dump((X_train, X_test, y_train, y_test), models_dir / 'train_test_data.joblib')\n",
    "\n",
    "# Scaling features\n",
    "print(\"\\nScaling features...\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Save the scaler for future use\n",
    "joblib.dump(scaler, models_dir / 'scaler.joblib')\n",
    "\n",
    "# Model training\n",
    "print(\"\\nTraining models...\")\n",
    "\n",
    "# Adjusted alpha values for Ridge Regression and Lasso Regression to avoid numerical instability\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': RidgeCV(alphas=np.logspace(-3, 3, 7), cv=5),\n",
    "    'ElasticNet': ElasticNetCV(alphas=np.logspace(-4, -0.5, 30), l1_ratio=[0.1, 0.5, 0.9], cv=5, max_iter=10000),\n",
    "    'Lasso Regression': LassoCV(alphas=np.logspace(-3, -0.5, 30), cv=5, max_iter=10000),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(\n",
    "        n_estimators=300, learning_rate=0.05, max_depth=3,\n",
    "        min_samples_leaf=5, max_features=0.8, random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(\n",
    "        n_estimators=100, max_depth=None, max_features='sqrt',\n",
    "        min_samples_leaf=2, random_state=42),\n",
    "    'XGBoost': XGBRegressor(\n",
    "        n_estimators=300, learning_rate=0.05, max_depth=5,\n",
    "        min_child_weight=3, subsample=0.8, colsample_bytree=0.8, random_state=42)\n",
    "}\n",
    "\n",
    "# Model evaluation\n",
    "print(\"\\nEvaluating models...\")\n",
    "results = {'Model': [], 'MAE': [], 'RMSE': [], 'R² Score': []}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    model_filename = f\"{name.replace(' ', '_').lower()}_model.joblib\"\n",
    "    # Save the trained model\n",
    "    joblib.dump(model, os.path.join(models_dir, model_filename))\n",
    "    # Make predictions on the test set\n",
    "    predictions = model.predict(X_test_scaled)\n",
    "    # Calculate performance metrics\n",
    "    y_test_exp = np.expm1(y_test)\n",
    "    predictions_exp = np.expm1(predictions)\n",
    "    # Handle any negative predictions due to model limitations\n",
    "    predictions_exp[predictions_exp < 0] = 0\n",
    "    mae = mean_absolute_error(y_test_exp, predictions_exp)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_exp, predictions_exp))\n",
    "    r2 = r2_score(y_test_exp, predictions_exp)\n",
    "    # Store results\n",
    "    results['Model'].append(name)\n",
    "    results['MAE'].append(mae)\n",
    "    results['RMSE'].append(rmse)\n",
    "    results['R² Score'].append(r2)\n",
    "    print(f\"{name} - MAE: {mae:.2f}, RMSE: {rmse:.2f}, R² Score: {r2:.4f}\")\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nModel Evaluation Results:\")\n",
    "print(results_df)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(os.path.join(models_dir, 'model_evaluation.csv'), index=False)\n",
    "\n",
    "# Save feature importances\n",
    "# Using the 'importances' Series from Random Forest\n",
    "feature_importances = importances.reset_index()\n",
    "feature_importances.columns = ['Feature', 'Importance']\n",
    "feature_importances.to_csv(os.path.join(models_dir, 'feature_importances.csv'), index=False)\n",
    "print(\"\\nSaved feature importances to 'feature_importances.csv'.\")\n",
    "\n",
    "# Process inherited houses\n",
    "print(\"\\nProcessing inherited houses...\")\n",
    "\n",
    "# Handle missing values in inherited_houses\n",
    "print(\"Handling missing values in inherited_houses...\")\n",
    "for feature in zero_fill_features:\n",
    "    inherited_houses[feature].fillna(0, inplace=True)\n",
    "    print(f\"Filled missing values in {feature} with 0.\")\n",
    "\n",
    "for feature, value in categorical_mode_fill.items():\n",
    "    inherited_houses[feature].fillna(value, inplace=True)\n",
    "    print(f\"Filled missing values in {feature} with '{value}'.\")\n",
    "\n",
    "for feature in numerical_median_fill:\n",
    "    median_value = house_data[feature].median()\n",
    "    inherited_houses[feature].fillna(median_value, inplace=True)\n",
    "    print(f\"Filled missing values in {feature} with median value {median_value}.\")\n",
    "\n",
    "# Encode categorical features\n",
    "print(\"Encoding categorical features in inherited_houses...\")\n",
    "for col, mapping in ordinal_mappings.items():\n",
    "    if col in inherited_houses.columns:\n",
    "        inherited_houses[col] = inherited_houses[col].map(mapping)\n",
    "        print(f\"Encoded {col} using ordinal mapping.\")\n",
    "\n",
    "# Feature engineering on inherited houses\n",
    "print(\"Performing feature engineering on inherited_houses...\")\n",
    "inherited_houses['TotalSF'] = inherited_houses['TotalBsmtSF'] + inherited_houses['1stFlrSF'] + inherited_houses['2ndFlrSF']\n",
    "print(\"Created TotalSF feature.\")\n",
    "inherited_houses['Qual_TotalSF'] = inherited_houses['OverallQual'] * inherited_houses['TotalSF']\n",
    "print(\"Created Qual_TotalSF feature.\")\n",
    "\n",
    "# Transform skewed features\n",
    "print(\"\\nTransforming skewed features in inherited_houses...\")\n",
    "for feat in skewed_features:\n",
    "    if feat in inherited_houses.columns:\n",
    "        if (inherited_houses[feat] <= 0).any():\n",
    "            inherited_houses[feat] = np.log1p(inherited_houses[feat])\n",
    "            print(f\"Applied log1p transformation to {feat}.\")\n",
    "        else:\n",
    "            lam = lam_dict.get(feat)\n",
    "            if lam is not None:\n",
    "                try:\n",
    "                    inherited_houses[feat] = boxcox(inherited_houses[feat], lam)\n",
    "                    print(f\"Applied box-cox transformation to {feat} with lambda {lam:.4f}.\")\n",
    "                except ValueError:\n",
    "                    inherited_houses[feat] = np.log1p(inherited_houses[feat])\n",
    "                    print(f\"Applied log1p transformation to {feat} (box-cox failed).\")\n",
    "            else:\n",
    "                inherited_houses[feat] = np.log1p(inherited_houses[feat])\n",
    "                print(f\"Applied log1p transformation to {feat} (no lambda found).\")\n",
    "\n",
    "# Ensure the features match\n",
    "inherited_houses = inherited_houses.reindex(columns=selected_features, fill_value=0)\n",
    "print(\"\\nReindexed inherited_houses to match selected features.\")\n",
    "\n",
    "# Scaling\n",
    "print(\"Scaling inherited houses features...\")\n",
    "inherited_houses_scaled = scaler.transform(inherited_houses)\n",
    "\n",
    "# Predictions\n",
    "print(\"\\nMaking predictions on inherited houses...\")\n",
    "predictions_df = pd.DataFrame()\n",
    "for name, model in models.items():\n",
    "    predictions_log = model.predict(inherited_houses_scaled)\n",
    "    predictions_actual = np.expm1(predictions_log)\n",
    "    # Handle negative predictions\n",
    "    predictions_actual[predictions_actual < 0] = 0\n",
    "    # Store predictions\n",
    "    predictions_df[name] = predictions_actual\n",
    "    print(f\"Predictions made using {name}.\")\n",
    "\n",
    "# Save predictions to CSV\n",
    "predictions_df.to_csv(os.path.join(models_dir, 'inherited_houses_predictions.csv'), index=False)\n",
    "print(\"\\nPredictions saved to 'inherited_houses_predictions.csv'.\")\n",
    "\n",
    "# Optional: Display the predictions\n",
    "print(\"\\nPredictions for Inherited Houses:\")\n",
    "print(predictions_df)\n",
    "\n",
    "# Save the final model (best performing model)\n",
    "best_model_name = results_df.sort_values('RMSE').iloc[0]['Model']\n",
    "print(f\"\\nBest performing model is {best_model_name}. Saving as final_model.joblib.\")\n",
    "joblib.dump(models[best_model_name], os.path.join(models_dir, 'final_model.joblib'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
